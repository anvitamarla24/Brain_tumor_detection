{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from skimage import io\n",
    "from PIL import Image \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        #zoom_range=0.01,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "yes_image_path = 'C:/Users/anvit/OneDrive/Desktop/Project_1/brain_tumor_dataset/yes'\n",
    "yes_count = 5\n",
    "for img in os.listdir(yes_image_path):\n",
    "    img = cv2.imread(yes_image_path + '\\\\' + img)\n",
    "    img = img_to_array(img)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(img, batch_size=1,save_to_dir='C:/Users/anvit/OneDrive/Desktop/Project_1/brain_tumor_dataset/yes_aug', save_prefix='aug_', save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > yes_count:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "\n",
    "no_image_path = 'C:/Users/anvit/OneDrive/Desktop/Project_1/brain_tumor_dataset/no'\n",
    "no_count = 8\n",
    "for img in os.listdir(no_image_path):\n",
    "    img = cv2.imread(no_image_path + '\\\\' + img)\n",
    "    img = img_to_array(img)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(img, batch_size=1,save_to_dir='C:/Users/anvit/OneDrive/Desktop/Project_1/brain_tumor_dataset/no_aug', save_prefix='aug_', save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > no_count:\n",
    "            break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes_images = os.listdir('C:/Users/anvit/OneDrive/Desktop/Project_1/brain_tumor_dataset/yes_aug/')\n",
    "no_images = os.listdir('C:/Users/anvit/OneDrive/Desktop/Project_1/brain_tumor_dataset/no_aug/')\n",
    "data = np.concatenate([yes_images, no_images])\n",
    "len(data) == len(yes_images) + len(no_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pos = np.full(len(yes_images), 1)\n",
    "target_neg = np.full(len(no_images), 0)\n",
    "target_data = np.concatenate([target_pos, target_neg])\n",
    "len(target_data)==len(target_pos) + len(target_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = []\n",
    "for image in yes_images:\n",
    "    img = cv2.imread('C:/Users/anvit/OneDrive/Desktop/Project_1/brain_tumor_dataset/yes_aug/' + image)\n",
    "    face = cv2.resize(img, (256, 256))\n",
    "    (b, g, r)=cv2.split(face) \n",
    "    img=cv2.merge([r,g,b])\n",
    "    split_data.append(face)\n",
    "    \n",
    "for image in no_images:\n",
    "    img = cv2.imread('C:/Users/anvit/OneDrive/Desktop/Project_1/brain_tumor_dataset/no_aug/' + image)\n",
    "    face = cv2.resize(img, (256, 256))\n",
    "    (b, g, r)=cv2.split(face) \n",
    "    img=cv2.merge([r,g,b])\n",
    "    split_data.append(face)\n",
    "\n",
    "d = np.squeeze(split_data)\n",
    "\n",
    "# normalize data\n",
    "d = d.astype('float32')\n",
    "d /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.reshape((d.shape[0],3*256*256))\n",
    "\n",
    "d[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6228571428571429\n",
      "Precision: 0.6323529411764706\n",
      "Recall: 0.6370370370370371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[155, 100],\n",
       "       [ 98, 172]], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(d, target_data, test_size=0.3,random_state=109) # 70% training and 30% test\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Precision means the percentage of your results which are relevant. \n",
    "# Recall refers to the percentage of total relevant results correctly classified by your algorithm .\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# Import the modules from `sklearn.metrics`\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Import `Dense` from `keras.layers`\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model.add(Dense(12, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# model.add(Dense(4, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 12)                2359308   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,359,421\n",
      "Trainable params: 2,359,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.00283215,  0.00296249, -0.0006153 , ..., -0.0014063 ,\n",
       "          0.0002464 ,  0.00292327],\n",
       "        [-0.00254285, -0.00187897, -0.00240497, ..., -0.00464575,\n",
       "         -0.00310043,  0.00244491],\n",
       "        [ 0.00260958, -0.00031329,  0.00370067, ...,  0.00403761,\n",
       "          0.00126235, -0.00355883],\n",
       "        ...,\n",
       "        [-0.00510662, -0.00543411, -0.00522314, ...,  0.00274838,\n",
       "          0.00184199, -0.00510768],\n",
       "        [ 0.0002711 , -0.00196035,  0.00526764, ...,  0.00285973,\n",
       "         -0.00233865,  0.00110698],\n",
       "        [ 0.00550295, -0.00408611, -0.0026018 , ...,  0.00241917,\n",
       "          0.00406503,  0.00040266]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.45869792, -0.34199947, -0.26047167,  0.52022564, -0.10104331,\n",
       "          0.04562664, -0.41777444, -0.43314168],\n",
       "        [ 0.3402555 ,  0.26241308,  0.5203072 , -0.51215965,  0.20781642,\n",
       "         -0.29071435,  0.05908096,  0.2548346 ],\n",
       "        [ 0.09723955, -0.21254393, -0.37767816,  0.5132711 ,  0.4707724 ,\n",
       "         -0.22848639,  0.36323452, -0.5290174 ],\n",
       "        [ 0.47989678,  0.06786084,  0.41537893,  0.33556217, -0.20273095,\n",
       "         -0.08742216, -0.25586364,  0.5107299 ],\n",
       "        [-0.17121789, -0.22448546, -0.19727123,  0.18120676,  0.26933122,\n",
       "          0.01771259,  0.00058073,  0.2047723 ],\n",
       "        [-0.46138993, -0.39777094,  0.378286  , -0.39035243,  0.22734702,\n",
       "         -0.06383705, -0.22588953, -0.5362201 ],\n",
       "        [ 0.0708338 , -0.2352823 ,  0.2031765 ,  0.07212466, -0.49940583,\n",
       "          0.16008049,  0.34785908,  0.49903297],\n",
       "        [-0.02076256, -0.4714997 ,  0.22469181, -0.20233357,  0.36959976,\n",
       "          0.3650685 ,  0.2297467 , -0.24823341],\n",
       "        [ 0.29924154,  0.5077621 , -0.3687564 ,  0.36296034,  0.37486893,\n",
       "          0.1438908 , -0.4697915 , -0.3347155 ],\n",
       "        [-0.06898805,  0.47942984,  0.0635128 ,  0.0457502 , -0.01567608,\n",
       "          0.51576245,  0.18383485,  0.33816636],\n",
       "        [ 0.3895514 ,  0.08603007,  0.41280335, -0.09053639, -0.08728072,\n",
       "          0.12363857, -0.36738396,  0.0451017 ],\n",
       "        [ 0.47921395,  0.10305423,  0.327325  ,  0.20490718,  0.4413572 ,\n",
       "          0.14774317,  0.3748598 , -0.43038237]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.4050394 ],\n",
       "        [-0.48655018],\n",
       "        [-0.16470873],\n",
       "        [ 0.32272542],\n",
       "        [-0.56023103],\n",
       "        [ 0.5114831 ],\n",
       "        [-0.38652432],\n",
       "        [ 0.19686186]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1224/1224 [==============================] - 7s 6ms/step - loss: 3.3466 - accuracy: 0.5662\n",
      "Epoch 2/100\n",
      "1224/1224 [==============================] - 4s 4ms/step - loss: 0.7724 - accuracy: 0.6863\n",
      "Epoch 3/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.5615 - accuracy: 0.7181\n",
      "Epoch 4/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.6788 - accuracy: 0.6871\n",
      "Epoch 5/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.6082 - accuracy: 0.7214\n",
      "Epoch 6/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.5210 - accuracy: 0.7549\n",
      "Epoch 7/100\n",
      "1224/1224 [==============================] - 4s 4ms/step - loss: 0.5867 - accuracy: 0.7157\n",
      "Epoch 8/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.4746 - accuracy: 0.7770\n",
      "Epoch 9/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.5035 - accuracy: 0.7672: 1s - loss: 0.4421 - accu\n",
      "Epoch 10/100\n",
      "1224/1224 [==============================] - 4s 4ms/step - loss: 0.3836 - accuracy: 0.8211\n",
      "Epoch 11/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.3846 - accuracy: 0.8252\n",
      "Epoch 12/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.4404 - accuracy: 0.7998: 2s - loss:\n",
      "Epoch 13/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.3506 - accuracy: 0.8399\n",
      "Epoch 14/100\n",
      "1224/1224 [==============================] - 4s 4ms/step - loss: 0.3187 - accuracy: 0.8717\n",
      "Epoch 15/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2869 - accuracy: 0.8962\n",
      "Epoch 16/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.3906 - accuracy: 0.8276\n",
      "Epoch 17/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.3266 - accuracy: 0.8562\n",
      "Epoch 18/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2575 - accuracy: 0.9134\n",
      "Epoch 19/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2447 - accuracy: 0.9183\n",
      "Epoch 20/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2459 - accuracy: 0.9093\n",
      "Epoch 21/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2134 - accuracy: 0.9461\n",
      "Epoch 22/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2119 - accuracy: 0.9379\n",
      "Epoch 23/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.4275 - accuracy: 0.7949\n",
      "Epoch 24/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2242 - accuracy: 0.9191\n",
      "Epoch 25/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2306 - accuracy: 0.9183\n",
      "Epoch 26/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.3016 - accuracy: 0.8603\n",
      "Epoch 27/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2183 - accuracy: 0.9158\n",
      "Epoch 28/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.1813 - accuracy: 0.9420\n",
      "Epoch 29/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.2019 - accuracy: 0.9240\n",
      "Epoch 30/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.1803 - accuracy: 0.9444\n",
      "Epoch 31/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.1442 - accuracy: 0.9706\n",
      "Epoch 32/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.1345 - accuracy: 0.9747\n",
      "Epoch 33/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.1441 - accuracy: 0.9673\n",
      "Epoch 34/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.1200 - accuracy: 0.9788\n",
      "Epoch 35/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.1668 - accuracy: 0.9428\n",
      "Epoch 36/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.3599 - accuracy: 0.8456\n",
      "Epoch 37/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.1488 - accuracy: 0.9518\n",
      "Epoch 38/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.1314 - accuracy: 0.9665\n",
      "Epoch 39/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0956 - accuracy: 0.9877\n",
      "Epoch 40/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0903 - accuracy: 0.9886\n",
      "Epoch 41/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0927 - accuracy: 0.9902\n",
      "Epoch 42/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0811 - accuracy: 0.9951\n",
      "Epoch 43/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0776 - accuracy: 0.9984\n",
      "Epoch 44/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0895 - accuracy: 0.9837: \n",
      "Epoch 45/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0679 - accuracy: 0.9992\n",
      "Epoch 46/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0989 - accuracy: 0.9796\n",
      "Epoch 47/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0643 - accuracy: 0.9959\n",
      "Epoch 48/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0690 - accuracy: 0.9967\n",
      "Epoch 49/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0611 - accuracy: 0.9951\n",
      "Epoch 50/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0823 - accuracy: 0.9886: \n",
      "Epoch 51/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0587 - accuracy: 0.9959\n",
      "Epoch 52/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0458 - accuracy: 0.9992\n",
      "Epoch 53/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0453 - accuracy: 0.9984\n",
      "Epoch 54/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0580 - accuracy: 0.9951\n",
      "Epoch 55/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0477 - accuracy: 0.9975\n",
      "Epoch 56/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0405 - accuracy: 0.9992: 0s - loss: 0.0405 - accuracy: 0.99\n",
      "Epoch 57/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0436 - accuracy: 0.9992: 1s - loss: 0.043\n",
      "Epoch 59/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0320 - accuracy: 1.0000: 0s - loss: 0.0319 - accuracy\n",
      "Epoch 61/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0374 - accuracy: 0.9992\n",
      "Epoch 62/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0260 - accuracy: 1.0000: 3s\n",
      "Epoch 64/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0274 - accuracy: 1.0000: 2s - loss: 0\n",
      "Epoch 66/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0240 - accuracy: 1.0000: 2s - loss: 0.0\n",
      "Epoch 68/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1224/1224 [==============================] - 4s 4ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 1.0000: 0s - loss: 0.0124 - accuracy: \n",
      "Epoch 84/100\n",
      "1224/1224 [==============================] - 5s 4ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0078 - accuracy: 1.0000: 0s - loss: 0.0078 - accuracy: 1.\n",
      "Epoch 98/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1224/1224 [==============================] - 4s 3ms/step - loss: 0.0074 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525/525 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7252053778512138, 0.6228571534156799]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 979 samples, validate on 245 samples\n",
      "Epoch 1/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 3/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 4/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 5/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 6/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 7/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 8/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 9/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 10/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 11/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 12/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 13/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 14/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 15/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 16/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 17/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 18/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 19/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 20/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 21/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 22/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 23/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 24/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 25/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 26/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 27/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 28/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 29/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 30/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 31/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 32/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 33/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 34/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 35/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 36/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 37/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 38/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 39/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 40/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 41/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 42/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 43/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 44/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 45/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 46/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 47/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 48/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 49/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 50/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 51/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 52/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 53/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 54/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 55/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 56/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 57/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 58/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 59/250\n",
      "979/979 [==============================] - 318s 324ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 60/250\n",
      "979/979 [==============================] - 5s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 61/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 62/250\n",
      "979/979 [==============================] - 5s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 63/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 64/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 65/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 66/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 67/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 68/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 69/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 70/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 71/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 72/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 73/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 74/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 75/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 76/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 77/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 78/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 79/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 80/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 81/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 82/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 83/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 84/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 85/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 86/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 87/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9959\n",
      "Epoch 88/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9959\n",
      "Epoch 89/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 90/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 91/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 92/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 93/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 94/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 95/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 96/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 97/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 98/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 99/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 100/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 101/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.9419e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 102/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.7208e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9959\n",
      "Epoch 103/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.7552e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9959\n",
      "Epoch 104/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.5922e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9959\n",
      "Epoch 105/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.4376e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 106/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.3916e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9959\n",
      "Epoch 107/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.4789e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 108/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.7353e-04 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9959\n",
      "Epoch 109/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.6830e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9959\n",
      "Epoch 110/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 9.1191e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 111/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 8.8853e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9959\n",
      "Epoch 112/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 8.5977e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9959\n",
      "Epoch 113/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 8.6062e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9959\n",
      "Epoch 114/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 8.5696e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9959\n",
      "Epoch 115/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 8.3943e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9959\n",
      "Epoch 116/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 8.1665e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9959\n",
      "Epoch 117/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 8.2172e-04 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9959\n",
      "Epoch 118/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 8.4219e-04 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9959\n",
      "Epoch 119/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 7.8289e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9959\n",
      "Epoch 120/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 7.7161e-04 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9959\n",
      "Epoch 121/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 8.0383e-04 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9918\n",
      "Epoch 122/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 8.1392e-04 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9959\n",
      "Epoch 123/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 7.7174e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9959\n",
      "Epoch 124/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 7.9062e-04 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9959\n",
      "Epoch 125/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 7.4530e-04 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9918\n",
      "Epoch 126/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 7.5076e-04 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9959\n",
      "Epoch 127/250\n",
      "979/979 [==============================] - 5s 5ms/step - loss: 7.0134e-04 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9918\n",
      "Epoch 128/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 6.9792e-04 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9959\n",
      "Epoch 129/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 6.9866e-04 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9959\n",
      "Epoch 130/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 6.9203e-04 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9918\n",
      "Epoch 131/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 6.9066e-04 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9918\n",
      "Epoch 132/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 6.6968e-04 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9918\n",
      "Epoch 133/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 6.4971e-04 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9959\n",
      "Epoch 134/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 6.5492e-04 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9918\n",
      "Epoch 135/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 6.3109e-04 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9918\n",
      "Epoch 136/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 6.2849e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9918\n",
      "Epoch 137/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 6.2488e-04 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9918\n",
      "Epoch 138/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 6.1990e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9918\n",
      "Epoch 139/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 6.0622e-04 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9918\n",
      "Epoch 140/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.9517e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9918\n",
      "Epoch 141/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 6.0382e-04 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9918\n",
      "Epoch 142/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 6.1351e-04 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9918\n",
      "Epoch 143/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.7514e-04 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9918\n",
      "Epoch 144/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.7016e-04 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9918\n",
      "Epoch 145/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.6133e-04 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
      "Epoch 146/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.7467e-04 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9918\n",
      "Epoch 147/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.4965e-04 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9918\n",
      "Epoch 148/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.4474e-04 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9918\n",
      "Epoch 149/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.3224e-04 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9918\n",
      "Epoch 150/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.2599e-04 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9918\n",
      "Epoch 151/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.2047e-04 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9918\n",
      "Epoch 152/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.2233e-04 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9918\n",
      "Epoch 153/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 5.0909e-04 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9918\n",
      "Epoch 154/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 5.2006e-04 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9918\n",
      "Epoch 155/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.9311e-04 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9918\n",
      "Epoch 156/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.9246e-04 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9918\n",
      "Epoch 157/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.8362e-04 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9918\n",
      "Epoch 158/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.8180e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9918\n",
      "Epoch 159/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.7764e-04 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9918\n",
      "Epoch 160/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.6995e-04 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9918\n",
      "Epoch 161/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.6792e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9796\n",
      "Epoch 162/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.7336e-04 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9918\n",
      "Epoch 163/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.5952e-04 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9918\n",
      "Epoch 164/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.5224e-04 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9878\n",
      "Epoch 165/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.4496e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9878\n",
      "Epoch 166/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.4005e-04 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9918\n",
      "Epoch 167/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.4064e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9796\n",
      "Epoch 168/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.4639e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9755\n",
      "Epoch 169/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.2401e-04 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9878\n",
      "Epoch 170/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.1673e-04 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9878\n",
      "Epoch 171/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.2145e-04 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9918\n",
      "Epoch 172/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.1266e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9837\n",
      "Epoch 173/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 4.0781e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9796\n",
      "Epoch 174/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.9898e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9878\n",
      "Epoch 175/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.9499e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9796\n",
      "Epoch 176/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 3.9592e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9796\n",
      "Epoch 177/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.8459e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9918\n",
      "Epoch 178/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.7836e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9878\n",
      "Epoch 179/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.7534e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9878\n",
      "Epoch 180/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.7122e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9878\n",
      "Epoch 181/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.6627e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9796\n",
      "Epoch 182/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.6309e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9796\n",
      "Epoch 183/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.6112e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9796\n",
      "Epoch 184/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 3.5480e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9878\n",
      "Epoch 185/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.5843e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9878\n",
      "Epoch 186/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 3.5030e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9796\n",
      "Epoch 187/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.4156e-04 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9673\n",
      "Epoch 188/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.4127e-04 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9796\n",
      "Epoch 189/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 3.3709e-04 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9796\n",
      "Epoch 190/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.3249e-04 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9796\n",
      "Epoch 191/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 3.2764e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9755\n",
      "Epoch 192/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.2454e-04 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9837\n",
      "Epoch 193/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.2184e-04 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9755\n",
      "Epoch 194/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.1588e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9796\n",
      "Epoch 195/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 3.1489e-04 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9796\n",
      "Epoch 196/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 3.0937e-04 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9755\n",
      "Epoch 197/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.0912e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9755\n",
      "Epoch 198/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 3.0458e-04 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9755\n",
      "Epoch 199/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.9935e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9755\n",
      "Epoch 200/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 2.9754e-04 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9755\n",
      "Epoch 201/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 2.9498e-04 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9755\n",
      "Epoch 202/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.9782e-04 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9755\n",
      "Epoch 203/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.8562e-04 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9714\n",
      "Epoch 204/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.8605e-04 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9673\n",
      "Epoch 205/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 2.8490e-04 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9755\n",
      "Epoch 206/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.7723e-04 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9755\n",
      "Epoch 207/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.7493e-04 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9755\n",
      "Epoch 208/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.8333e-04 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9755\n",
      "Epoch 209/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.6792e-04 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9714\n",
      "Epoch 210/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 2.6467e-04 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9714\n",
      "Epoch 211/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 2.6973e-04 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9633\n",
      "Epoch 212/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.6501e-04 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9633\n",
      "Epoch 213/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.6526e-04 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9633\n",
      "Epoch 214/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 2.6197e-04 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9633\n",
      "Epoch 215/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 2.5129e-04 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9755\n",
      "Epoch 216/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.4932e-04 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9714\n",
      "Epoch 217/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.4469e-04 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9714\n",
      "Epoch 218/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.4309e-04 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.9755\n",
      "Epoch 219/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 2.4223e-04 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9755\n",
      "Epoch 220/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 2.5132e-04 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 0.9755\n",
      "Epoch 221/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.3854e-04 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9755\n",
      "Epoch 222/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.4371e-04 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9755\n",
      "Epoch 223/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 2.3739e-04 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9755\n",
      "Epoch 224/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 2.3093e-04 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9714\n",
      "Epoch 225/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.2707e-04 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9714\n",
      "Epoch 226/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.2391e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9755\n",
      "Epoch 227/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.2562e-04 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9714\n",
      "Epoch 228/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 2.2489e-04 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9673\n",
      "Epoch 229/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 2.1896e-04 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9673\n",
      "Epoch 230/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 2.1461e-04 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9673\n",
      "Epoch 231/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.1186e-04 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9673\n",
      "Epoch 232/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 2.0869e-04 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9673\n",
      "Epoch 233/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 2.0621e-04 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9673\n",
      "Epoch 234/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.0394e-04 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9673\n",
      "Epoch 235/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.0814e-04 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9633\n",
      "Epoch 236/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 2.0768e-04 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9673\n",
      "Epoch 237/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.9796e-04 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9673\n",
      "Epoch 238/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 1.9653e-04 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9673\n",
      "Epoch 239/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.9307e-04 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9633\n",
      "Epoch 240/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.9367e-04 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9633\n",
      "Epoch 241/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.9185e-04 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9673\n",
      "Epoch 242/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.8875e-04 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9673\n",
      "Epoch 243/250\n",
      "979/979 [==============================] - 3s 4ms/step - loss: 1.8541e-04 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9592\n",
      "Epoch 244/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.9065e-04 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9592\n",
      "Epoch 245/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.8443e-04 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9673\n",
      "Epoch 246/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.8071e-04 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9592\n",
      "Epoch 247/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.7938e-04 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9592\n",
      "Epoch 248/250\n",
      "979/979 [==============================] - 4s 4ms/step - loss: 1.7800e-04 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9673\n",
      "Epoch 249/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.7418e-04 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9673\n",
      "Epoch 250/250\n",
      "979/979 [==============================] - 3s 3ms/step - loss: 1.7372e-04 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9633\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=250, batch_size=64, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[169,  86],\n",
       "       [112, 158]], dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the modules from `sklearn.metrics`\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6475409836065574"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5851851851851851"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1101 samples, validate on 123 samples\n",
      "Epoch 1/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 7.5574e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 7.0950e-04 - accuracy: 1.0000 - val_loss: 8.4512e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 6.9273e-04 - accuracy: 1.0000 - val_loss: 8.8300e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 6.8202e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 6.4951e-04 - accuracy: 1.0000 - val_loss: 9.3096e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 6.3407e-04 - accuracy: 1.0000 - val_loss: 9.0093e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 6.3755e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 6.5066e-04 - accuracy: 1.0000 - val_loss: 9.3702e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 6.0191e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 5.8232e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 5.9374e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 5.5903e-04 - accuracy: 1.0000 - val_loss: 9.8976e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 5.3735e-04 - accuracy: 1.0000 - val_loss: 9.9001e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 5.3624e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 5.2186e-04 - accuracy: 1.0000 - val_loss: 9.9267e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 5.1309e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 4.9404e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 4.8603e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 4.7498e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 4.7030e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 4.7441e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 4.5358e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 4.4264e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 4.3703e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 4.3597e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 4.1496e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 4.1482e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 3.9849e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.9012e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.9805e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 3.7740e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.7532e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.6106e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.5363e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.5779e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.4095e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.3591e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.2800e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.2169e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.2723e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.1455e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.0722e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 3.0067e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 3.0588e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.9249e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.9003e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.8201e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.7602e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.7453e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.6789e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.7348e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.6768e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.5787e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 2.5445e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 2.5036e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 2.5588e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.6317e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.4334e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.3513e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.2827e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.2488e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.1939e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.1823e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.1268e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.1789e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 2.0888e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 2.0395e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.9892e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 1.9827e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.9849e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 1.9005e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 1.8863e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 1.8826e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.8231e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.8006e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.7774e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.7402e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 1.7637e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 1.6812e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.6617e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.6407e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.6150e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.5982e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 1.5600e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.5606e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.5859e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.5593e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.5244e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.4718e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.4512e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.3999e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.4089e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.3766e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.4152e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.3614e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1101/1101 [==============================] - 3s 3ms/step - loss: 1.3157e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.3115e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.2757e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.2597e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1101/1101 [==============================] - 3s 2ms/step - loss: 1.2488e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-07fb49f29818>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "history = model.fit(X_train, y_train, validation_split = 0.1, epochs= 100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
